{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data visualization throttled:\n",
    "Unthrottled memory power = ~3000\n",
    "\n",
    "| # | Setting |\n",
    "| --- | --- |\n",
    "| Device | macbook pro 14-inch, 2023 | \n",
    "| Chip | Apple M2 Pro | \n",
    "| Memory | 16 GB | \n",
    "| macOS | 15.1.1 | \n",
    "| Java | openjdk 21.0.5 | \n",
    "| Node | v23.3.0 | \n",
    "| Angular | v18.2.x | \n",
    "\n",
    "## Throttling\n",
    "\n",
    "| # | Setting |\n",
    "| --- | --- |\n",
    "| CPU | 4x CPU slowdown | \n",
    "| download | 1.6 Mbps | \n",
    "| upload | 750 Kbps | \n",
    "| latency | 150ms | \n",
    "\n",
    "## Core Web Vitals Measurements:\n",
    "\n",
    "**Long task**\n",
    "- Task that takes more than 50ms\n",
    "\n",
    "**TTFB (Time to First Byte):**\n",
    " - Time from navigation start until the first byte of response is received\n",
    " - Calculated using: performance.getEntriesByType('navigation')[0].responseStart\n",
    " \n",
    "**FCP (First Contentful Paint):**\n",
    " - Time when the first text, image, or other content appears on the screen.\n",
    " - Is the 'endTime' of the first-contentful-paint\n",
    " - FCP includes all things that happened before it (like TTFB).\n",
    " \n",
    "**LCP (Largest Contentful Paint):**\n",
    " - Time when the largest text or image element is rendered on the screen (so endTime)\n",
    " - Is the 'endTime' of the largest-contentful-paint.\n",
    " - FCP includes all things that happened before it (like TTFB).\n",
    " \n",
    "**TTI (Time to Interactive):**\n",
    " - Time when the page becomes 'reliably' interactive\n",
    " - It is measured as the endtime of the last 'long task' after the FCP starttime\n",
    " - If no tasks are found, it is the end-time of the FCP.\n",
    " \n",
    "**TBT (Total Blocking Time):**\n",
    " - Sum of all \"blocking time\" for long tasks between start of FCP and TTI\n",
    " - Blocking time = accumulation of (task duration - 50ms) of each long task.\n",
    " - TBT contains a 'quiet window' of 5s, if this window is expired, the test will end.\n",
    " - The quiet window starts after the FCP. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run6path = '../../../data/core-web-vitals/testrun-6'\n",
    "run7path = '../../../data/core-web-vitals/testrun-7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import scipy.stats as stats\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "\n",
    "\n",
    "dataset_A = pd.read_csv(f'{run7path}/results-csr.csv', sep=',')\n",
    "dataset_B = pd.read_csv(f'{run7path}/results-ssrh.csv', sep=',')\n",
    "\n",
    "features = ['navTime', 'totalTime', 'lcp', 'fcp', 'ttfb', 'tbt', 'tti', 'longestTask', 'longTasks']\n",
    "target_features = ['lcp', 'fcp', 'ttfb', 'tbt', 'tti', 'navTime']\n",
    "\n",
    "# Remove Java warmup\n",
    "dataset_A = dataset_A.iloc[5:]\n",
    "dataset_B = dataset_B.iloc[5:]\n",
    "\n",
    "datasets =\t{\n",
    "  \"csr\": dataset_A,\n",
    "  \"ssrh\": dataset_B,\n",
    "}\n",
    "\n",
    "csr_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_histogram(d, f, loc):\n",
    "    loc.hist(datasets[d][f].dropna(), bins=30, alpha=0.7, label=d, edgecolor='k')\n",
    "    loc.set_title(d)\n",
    "    loc.set_ylabel('Frequency')\n",
    "    loc.set_xlabel(f'Distribution of {f}')\n",
    "    loc.legend()\n",
    "\n",
    "def graphs(plot_func, features, height=8):\n",
    "    rows = len(features)\n",
    "    cols = len(datasets)\n",
    "\n",
    "    _, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(20, height*rows))\n",
    "    plt.subplots_adjust(hspace=0.5)\n",
    "    for y, f in enumerate(features):\n",
    "        for x, d in enumerate(datasets):\n",
    "            plot_func(d, f, axes[y, x])\n",
    "    return plt\n",
    "\n",
    "plt = graphs(plot_histogram, target_features)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers(df, features, contamination=0.1):\n",
    "    clf = IsolationForest(contamination=contamination, random_state=42)\n",
    "    outliers = clf.fit_predict(df[features])\n",
    "    return outliers == 1\n",
    "\n",
    "# def plot_outliers(d, f, loc, mask):\n",
    "#     loc.hist(datasets[d][f][mask[d]], bins=30, alpha=0.7, label='Inliers', edgecolor='k')\n",
    "#     loc.hist(datasets[d][f][~mask[d]], bins=30, alpha=0.7, label='Outliers', color='red', edgecolor='k')\n",
    "#     loc.set_title(d)\n",
    "#     loc.set_ylabel('Frequency')\n",
    "#     loc.set_xlabel(f'Distribution of {f}')\n",
    "#     loc.legend()\n",
    "\n",
    "\n",
    "def plot_outliers(d, f, loc, mask):\n",
    "    loc.plot(datasets[d][f], label='dirty', color='gray', alpha=0.5)\n",
    "    loc.plot(datasets[d][f][mask[d]], label=d)\n",
    "    loc.plot(datasets[d][f][~mask[d]], label='outliers', color='red')\n",
    "\n",
    "    loc.set_title(d)\n",
    "    loc.set_ylabel(f'{f} Time (ms)') \n",
    "    loc.set_xlabel('test nr #') \n",
    "\n",
    "def visualize_outliers(features, masks, height=8):\n",
    "    rows = len(features)\n",
    "    cols = len(datasets)\n",
    "    \n",
    "    _, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(20, height*rows))\n",
    "    plt.subplots_adjust(hspace=0.5)\n",
    "    \n",
    "    for y, f in enumerate(features):\n",
    "        for x, d in enumerate(datasets):\n",
    "            plot_outliers(d, f, axes[y, x], masks)\n",
    "    return plt\n",
    "\n",
    "def print_outlier_stats(datasets, masks):\n",
    "    stats = {}\n",
    "    for name, df in datasets.items():\n",
    "        total = len(df)\n",
    "        outliers = (~masks[name]).sum()\n",
    "        pct = (outliers / total) * 100\n",
    "        stats[name] = {\n",
    "            'total': total,\n",
    "            'outliers': outliers,\n",
    "            'percentage': pct\n",
    "        }\n",
    "    \n",
    "    stats_df = pd.DataFrame({\n",
    "        'Total Points': [stats[name]['total'] for name in stats],\n",
    "        'Outliers': [stats[name]['outliers'] for name in stats],\n",
    "        'Percentage Removed': [f\"{stats[name]['percentage']:.1f}%\" for name in stats]\n",
    "    }, index=datasets.keys())\n",
    "    \n",
    "    return stats_df\n",
    "\n",
    "masks = {}\n",
    "cleaned_datasets = {}\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    mask = detect_outliers(df, target_features)\n",
    "    masks[name] = mask\n",
    "    cleaned_datasets[name] = df[mask].copy()\n",
    "\n",
    "print(print_outlier_stats(datasets, masks))\n",
    "\n",
    "visualize_outliers(target_features, masks)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ceildiv(a, b): return -(a // -b)\n",
    "\n",
    "def plot_box_plot(f, loc):\n",
    "    [loc.plot(cleaned_datasets[d][f], label=d) for d in cleaned_datasets]\n",
    "\n",
    "    loc.set_title(f)\n",
    "    loc.set_ylabel('Time (ms)') \n",
    "    loc.set_xlabel('test nr #') \n",
    "    loc.set_ylim(bottom=0)\n",
    "    loc.legend()\n",
    "\n",
    "def graphs(plot_func, features, height=10):\n",
    "    rows = len(features)\n",
    "\n",
    "    _, axes = plt.subplots(nrows=rows, figsize=(20, height*rows))\n",
    "    plt.subplots_adjust(hspace=0.3, top=0.95, bottom=0.05)  \n",
    "    for y, f in enumerate(features):\n",
    "        plot_func(f, axes[y])\n",
    "    return plt\n",
    "\n",
    "graphs(plot_box_plot, target_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    'ttfb': 'two-sided',\n",
    "    'fcp': 'two-sided', \n",
    "    'lcp': 'two-sided',\n",
    "    'tbt': 'two-sided',\n",
    "    'tti': 'two-sided'\n",
    "}\n",
    "\n",
    "keys = list(cleaned_datasets.keys())\n",
    "\n",
    "results = pd.DataFrame([\n",
    "    [metric, alt, stats.mannwhitneyu(cleaned_datasets[keys[0]][metric], \n",
    "                                   cleaned_datasets[keys[1]][metric], \n",
    "                                   alternative=alt)[1]]\n",
    "    for metric, alt in metrics.items()\n",
    "], columns=['metric', 'hypothesis', 'p_value'])\n",
    "\n",
    "results['adjusted_p'] = multipletests(results['p_value'], method='bonferroni')[1]\n",
    "results['significant'] = results['adjusted_p'] < 0.05\n",
    "\n",
    "compact_format = lambda x: '%.3e' % x if x < 0.00001 else '%.5f' % x\n",
    "results['p_value'] = results['p_value'].apply(compact_format)\n",
    "results['adjusted_p'] = results['adjusted_p'].apply(compact_format)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar_chart(feature, loc):\n",
    "    percentiles = {d: cleaned_datasets[d][feature].quantile(0.75) for d in datasets}\n",
    "    bars = loc.bar(percentiles.keys(), percentiles.values())\n",
    "    \n",
    "    baseline = list(percentiles.values())[0]\n",
    "    for i, bar in enumerate(bars):\n",
    "        height = bar.get_height()\n",
    "        percentage = ((height / baseline) - 1) * 100\n",
    "        label = f'100 %' if (i == 0) else f'{percentage:+.1f}%'\n",
    "        loc.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                label,\n",
    "                ha='center', va='bottom')\n",
    "    \n",
    "    loc.set_title(feature)\n",
    "    loc.set_ylabel('Average Time (ms)')\n",
    "    loc.set_xlabel('Dataset')\n",
    "\n",
    "def graphs(plot_func, features, height=10):\n",
    "    cols = len(features)\n",
    "    _, axes = plt.subplots(ncols=cols, figsize=(20, 5))\n",
    "    plt.subplots_adjust(hspace=0.3, wspace=0.5, top=0.95, bottom=0.05)\n",
    "    for y, f in enumerate(features):\n",
    "        plot_func(f, axes[y])\n",
    "    return plt\n",
    "\n",
    "graphs(plot_bar_chart, target_features)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_order = ['ttfb', 'fcp', 'tti', 'lcp', 'navTime'] \n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "x = np.arange(len(datasets))\n",
    "bar_width = 0.15 \n",
    "\n",
    "for i, metric in enumerate(metric_order):\n",
    "    values = [dataset[metric].quantile(0.75) for name, dataset in cleaned_datasets.items()]\n",
    "    position = x + (i - len(metrics)/2 + 0.5) * bar_width\n",
    "    plt.bar(position, values, bar_width, label=metric.upper())\n",
    "\n",
    "plt.xlabel('Datasets')\n",
    "plt.ylabel('Time (ms)')\n",
    "plt.title('Web Performance Metrics Comparison')\n",
    "plt.xticks(x, datasets.keys())\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
